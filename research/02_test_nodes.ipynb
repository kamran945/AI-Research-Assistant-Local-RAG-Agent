{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Github Repositories\\AI-Research-Assistant-Local-RAG-Agent-Ollama\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the API keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "\n",
    "from src.vectordb.create_vectordb import PinconeVectorDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"USE_GROQ\" == \"no\"):\n",
    "\n",
    "    llm = ChatOllama(model=os.getenv('OLLAMA_CHAT_MODEL'), temperature=0.)\n",
    "\n",
    "    llm_json = ChatOllama(model=os.getenv('OLLAMA_CHAT_MODEL'), temperature=0., format=\"json\")\n",
    "else:\n",
    "    llm = ChatGroq(model=\"llama-3.1-70b-versatile\",\n",
    "                        stop_sequences=\"[end]\",\n",
    "                        temperature=0.)\n",
    "    llm_json = ChatGroq(model=\"llama-3.1-70b-versatile\",\n",
    "                        stop_sequences=\"[end]\",\n",
    "                        temperature=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"datasource\": \"vectorstore\"}\n",
      "{\"datasource\": \"websearch\"}\n",
      "{\"datasource\": \"vectorstore\"}\n"
     ]
    }
   ],
   "source": [
    "from src.utils.prompts import router_instructions\n",
    "\n",
    "test_vectorstore_llm_json = llm_json.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [\n",
    "        HumanMessage(\n",
    "            content=\"what is rag?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "test_web_search = llm_json.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [\n",
    "        HumanMessage(\n",
    "            content=\"When were olymics 2024 held?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "test_vectorstore_2 = llm_json.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [\n",
    "        HumanMessage(\n",
    "            content=\"Retrieval augmented generation?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(test_vectorstore_llm_json.content)\n",
    "print(test_web_search.content)\n",
    "print(test_vectorstore_2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index local-rag-agent already exists.\n",
      "Index Stats:\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 334}},\n",
      " 'total_vector_count': 334}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x000001E693F31330>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.vectordb.create_vectordb import PinconeVectorDb, get_pinecone_retriever\n",
    "\n",
    "pc = PinconeVectorDb()\n",
    "pc.create_pinecone_index()\n",
    "\n",
    "retriever = get_pinecone_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "\n",
      "[Document(metadata={'Authors': 'Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak', 'Published': '2024-08-05', 'Summary': 'Implementing Retrieval-Augmented Generation (RAG) systems is inherently\\ncomplex, requiring deep understanding of data, use cases, and intricate design\\ndecisions. Additionally, evaluating these systems presents significant\\nchallenges, necessitating assessment of both retrieval accuracy and generative\\nquality through a multi-faceted approach. We introduce RAG Foundry, an\\nopen-source framework for augmenting large language models for RAG use cases.\\nRAG Foundry integrates data creation, training, inference and evaluation into a\\nsingle workflow, facilitating the creation of data-augmented datasets for\\ntraining and evaluating large language models in RAG settings. This integration\\nenables rapid prototyping and experimentation with various RAG techniques,\\nallowing users to easily generate datasets and train RAG models using internal\\nor specialized knowledge sources. We demonstrate the framework effectiveness by\\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\\nconfigurations, showcasing consistent improvements across three\\nknowledge-intensive datasets. Code is released as open-source in\\nhttps://github.com/IntelLabs/RAGFoundry.', 'Title': 'RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation'}, page_content='butions and any other form of processing needed\\nfor a given evaluation.\\nSee listing 4 for a configuration example; it con-\\ntains an answer processor that extracts an answer\\nfrom an output, and a list of metrics to run.\\n4\\nExperiments: RAG Tuning\\nTo illustrate the usage and usefulness of the\\nRAG FOUNDRY library, we experiment with sev-\\neral possible RAG improvements to LLMs, and\\nevaluate the results on three knowledge-intensive\\ntasks.\\n4.1\\nRAG Augmentation Techniques'), Document(metadata={'Authors': 'Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak', 'Published': '2024-08-05', 'Summary': 'Implementing Retrieval-Augmented Generation (RAG) systems is inherently\\ncomplex, requiring deep understanding of data, use cases, and intricate design\\ndecisions. Additionally, evaluating these systems presents significant\\nchallenges, necessitating assessment of both retrieval accuracy and generative\\nquality through a multi-faceted approach. We introduce RAG Foundry, an\\nopen-source framework for augmenting large language models for RAG use cases.\\nRAG Foundry integrates data creation, training, inference and evaluation into a\\nsingle workflow, facilitating the creation of data-augmented datasets for\\ntraining and evaluating large language models in RAG settings. This integration\\nenables rapid prototyping and experimentation with various RAG techniques,\\nallowing users to easily generate datasets and train RAG models using internal\\nor specialized knowledge sources. We demonstrate the framework effectiveness by\\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\\nconfigurations, showcasing consistent improvements across three\\nknowledge-intensive datasets. Code is released as open-source in\\nhttps://github.com/IntelLabs/RAGFoundry.', 'Title': 'RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation'}, page_content='RAG\\n0.876\\n0.821\\n0.836\\n0.294\\n0.685\\n0.895\\n0.530\\n0.281\\n-\\n-\\nRAG-sft\\n0.878\\n0.777\\n0.750\\n0.252\\n0.717\\n0.833\\n0.720\\n0.491\\n-\\n-\\nCoT\\n0.923\\n0.555\\n0.741\\n0.367\\n0.263\\n0.826\\n0.574\\n0.439\\n0.477\\n0.705\\nCoT-sft\\n0.795\\n0.793\\n0.749\\n0.386\\n0.749\\n0.839\\n0.620\\n0.458\\n0.631\\n0.853\\nLlama-3 8B\\nBaseline\\n0.722\\n-\\n-\\n0.200\\n-\\n-\\n0.560\\n0.366\\n-\\n-\\nRAG\\n0.828\\n0.783\\n0.746\\n0.285\\n0.610\\n0.861\\n0.556\\n0.398\\n-\\n-\\nRAG-sft\\n0.916\\n0.704\\n0.714\\n0.291\\n0.653\\n0.854\\n0.770\\n0.537\\n-\\n-\\nCoT\\n0.896\\n0.518\\n0.764\\n0.395\\n0.536\\n0.730\\n0.684\\n0.480\\n0.378\\n0.732\\nCoT-sft\\n0.851\\n0.808\\n0.697'), Document(metadata={'Authors': 'Shenglai Zeng, Jiankun Zhang, Pengfei He, Yue Xing, Yiding Liu, Han Xu, Jie Ren, Shuaiqiang Wang, Dawei Yin, Yi Chang, Jiliang Tang', 'Published': '2024-02-23', 'Summary': \"Retrieval-augmented generation (RAG) is a powerful technique to facilitate\\nlanguage model with proprietary and private data, where data privacy is a\\npivotal concern. Whereas extensive research has demonstrated the privacy risks\\nof large language models (LLMs), the RAG technique could potentially reshape\\nthe inherent behaviors of LLM generation, posing new privacy issues that are\\ncurrently under-explored. In this work, we conduct extensive empirical studies\\nwith novel attack methods, which demonstrate the vulnerability of RAG systems\\non leaking the private retrieval database. Despite the new risk brought by RAG\\non the retrieval data, we further reveal that RAG can mitigate the leakage of\\nthe LLMs' training data. Overall, we provide new insights in this paper for\\nprivacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG\\nsystems builders. Our code is available at\\nhttps://github.com/phycholosogy/RAG-privacy.\", 'Title': 'The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)'}, page_content='able at https://github.com/phycholosogy/RAG-\\nprivacy.\\n1\\nIntroduction\\nRetrieval-augmented generation (RAG) (Liu, 2022;\\nChase, 2022; Van Veen et al., 2023; Ram et al.,\\n2023; Shi et al., 2023) is an advanced natural lan-\\nguage processing technique that enhances text gen-\\neration by integrating information retrieved from\\na large corpus of documents. These techniques\\nenable RAG to produce accurate and contextually\\nrelevant outputs with augmented external knowl-\\nedge and have been widely used in various scenar-'), Document(metadata={'Authors': 'Shenglai Zeng, Jiankun Zhang, Pengfei He, Yue Xing, Yiding Liu, Han Xu, Jie Ren, Shuaiqiang Wang, Dawei Yin, Yi Chang, Jiliang Tang', 'Published': '2024-02-23', 'Summary': \"Retrieval-augmented generation (RAG) is a powerful technique to facilitate\\nlanguage model with proprietary and private data, where data privacy is a\\npivotal concern. Whereas extensive research has demonstrated the privacy risks\\nof large language models (LLMs), the RAG technique could potentially reshape\\nthe inherent behaviors of LLM generation, posing new privacy issues that are\\ncurrently under-explored. In this work, we conduct extensive empirical studies\\nwith novel attack methods, which demonstrate the vulnerability of RAG systems\\non leaking the private retrieval database. Despite the new risk brought by RAG\\non the retrieval data, we further reveal that RAG can mitigate the leakage of\\nthe LLMs' training data. Overall, we provide new insights in this paper for\\nprivacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG\\nsystems builders. Our code is available at\\nhttps://github.com/phycholosogy/RAG-privacy.\", 'Title': 'The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)'}, page_content='> > >\\n{Retrieved Context}\\n> > >\\nExtracted relevant parts:\\nthe query during the summary, while making minimal modifications to the context. Therefore, we created\\nthe following two prompts:\\nWhen summarizing, each extracted context and its corresponding query are placed in the respective\\npositions above.\\nA.3\\nPerformance Evaluation\\nFor different datasets, we have employed various methods to assess performance of RAG. For each dataset,'), Document(metadata={'Authors': 'Shenglai Zeng, Jiankun Zhang, Pengfei He, Yue Xing, Yiding Liu, Han Xu, Jie Ren, Shuaiqiang Wang, Dawei Yin, Yi Chang, Jiliang Tang', 'Published': '2024-02-23', 'Summary': \"Retrieval-augmented generation (RAG) is a powerful technique to facilitate\\nlanguage model with proprietary and private data, where data privacy is a\\npivotal concern. Whereas extensive research has demonstrated the privacy risks\\nof large language models (LLMs), the RAG technique could potentially reshape\\nthe inherent behaviors of LLM generation, posing new privacy issues that are\\ncurrently under-explored. In this work, we conduct extensive empirical studies\\nwith novel attack methods, which demonstrate the vulnerability of RAG systems\\non leaking the private retrieval database. Despite the new risk brought by RAG\\non the retrieval data, we further reveal that RAG can mitigate the leakage of\\nthe LLMs' training data. Overall, we provide new insights in this paper for\\nprivacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG\\nsystems builders. Our code is available at\\nhttps://github.com/phycholosogy/RAG-privacy.\", 'Title': 'The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)'}, page_content='None\\n245\\n27\\n34\\n-\\n-\\n-\\n213\\nRandom Noise+prompt\\n62\\n17\\n24\\n-\\n-\\n-\\n211\\nSystem Prompt+prompt\\n252\\n7\\n24\\n-\\n-\\n-\\n203\\nRAG-Chatdoctor\\n2\\n1\\n15\\n0\\n0\\n3\\n34\\nRAG-Wikitext\\n2\\n2\\n3\\n0\\n0\\n0\\n70\\nRAG-W3C-Email\\n4\\n17\\n21\\n20\\n65\\n66\\n33\\ncontent7 to the inputs.\\n5.2\\nTargeted Attack\\nWe performed targeted attacks as described in Sec-\\ntion 3.3 and the results are shown in Table 3. In\\nthis table, \"None\" means no retrieval data is in-\\ncluded, \"Random Noise\" and \"System Prompt\" de-\\nnote adding random characters and protective sys-')]\n"
     ]
    }
   ],
   "source": [
    "question = \"What is rag?\"\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "print(len(docs))\n",
    "print()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "butions and any other form of processing needed\n",
      "for a given evaluation.\n",
      "See listing 4 for a configuration example; it con-\n",
      "tains an answer processor that extracts an answer\n",
      "from an output, and a list of metrics to run.\n",
      "4\n",
      "Experiments: RAG Tuning\n",
      "To illustrate the usage and usefulness of the\n",
      "RAG FOUNDRY library, we experiment with sev-\n",
      "eral possible RAG improvements to LLMs, and\n",
      "evaluate the results on three knowledge-intensive\n",
      "tasks.\n",
      "4.1\n",
      "RAG Augmentation Techniques\n",
      "\n",
      "RAG\n",
      "0.876\n",
      "0.821\n",
      "0.836\n",
      "0.294\n",
      "0.685\n",
      "0.895\n",
      "0.530\n",
      "0.281\n",
      "-\n",
      "-\n",
      "RAG-sft\n",
      "0.878\n",
      "0.777\n",
      "0.750\n",
      "0.252\n",
      "0.717\n",
      "0.833\n",
      "0.720\n",
      "0.491\n",
      "-\n",
      "-\n",
      "CoT\n",
      "0.923\n",
      "0.555\n",
      "0.741\n",
      "0.367\n",
      "0.263\n",
      "0.826\n",
      "0.574\n",
      "0.439\n",
      "0.477\n",
      "0.705\n",
      "CoT-sft\n",
      "0.795\n",
      "0.793\n",
      "0.749\n",
      "0.386\n",
      "0.749\n",
      "0.839\n",
      "0.620\n",
      "0.458\n",
      "0.631\n",
      "0.853\n",
      "Llama-3 8B\n",
      "Baseline\n",
      "0.722\n",
      "-\n",
      "-\n",
      "0.200\n",
      "-\n",
      "-\n",
      "0.560\n",
      "0.366\n",
      "-\n",
      "-\n",
      "RAG\n",
      "0.828\n",
      "0.783\n",
      "0.746\n",
      "0.285\n",
      "0.610\n",
      "0.861\n",
      "0.556\n",
      "0.398\n",
      "-\n",
      "-\n",
      "RAG-sft\n",
      "0.916\n",
      "0.704\n",
      "0.714\n",
      "0.291\n",
      "0.653\n",
      "0.854\n",
      "0.770\n",
      "0.537\n",
      "-\n",
      "-\n",
      "CoT\n",
      "0.896\n",
      "0.518\n",
      "0.764\n",
      "0.395\n",
      "0.536\n",
      "0.730\n",
      "0.684\n",
      "0.480\n",
      "0.378\n",
      "0.732\n",
      "CoT-sft\n",
      "0.851\n",
      "0.808\n",
      "0.697\n",
      "\n",
      "able at https://github.com/phycholosogy/RAG-\n",
      "privacy.\n",
      "1\n",
      "Introduction\n",
      "Retrieval-augmented generation (RAG) (Liu, 2022;\n",
      "Chase, 2022; Van Veen et al., 2023; Ram et al.,\n",
      "2023; Shi et al., 2023) is an advanced natural lan-\n",
      "guage processing technique that enhances text gen-\n",
      "eration by integrating information retrieved from\n",
      "a large corpus of documents. These techniques\n",
      "enable RAG to produce accurate and contextually\n",
      "relevant outputs with augmented external knowl-\n",
      "edge and have been widely used in various scenar-\n",
      "\n",
      "> > >\n",
      "{Retrieved Context}\n",
      "> > >\n",
      "Extracted relevant parts:\n",
      "the query during the summary, while making minimal modifications to the context. Therefore, we created\n",
      "the following two prompts:\n",
      "When summarizing, each extracted context and its corresponding query are placed in the respective\n",
      "positions above.\n",
      "A.3\n",
      "Performance Evaluation\n",
      "For different datasets, we have employed various methods to assess performance of RAG. For each dataset,\n",
      "\n",
      "None\n",
      "245\n",
      "27\n",
      "34\n",
      "-\n",
      "-\n",
      "-\n",
      "213\n",
      "Random Noise+prompt\n",
      "62\n",
      "17\n",
      "24\n",
      "-\n",
      "-\n",
      "-\n",
      "211\n",
      "System Prompt+prompt\n",
      "252\n",
      "7\n",
      "24\n",
      "-\n",
      "-\n",
      "-\n",
      "203\n",
      "RAG-Chatdoctor\n",
      "2\n",
      "1\n",
      "15\n",
      "0\n",
      "0\n",
      "3\n",
      "34\n",
      "RAG-Wikitext\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "70\n",
      "RAG-W3C-Email\n",
      "4\n",
      "17\n",
      "21\n",
      "20\n",
      "65\n",
      "66\n",
      "33\n",
      "content7 to the inputs.\n",
      "5.2\n",
      "Targeted Attack\n",
      "We performed targeted attacks as described in Sec-\n",
      "tion 3.3 and the results are shown in Table 3. In\n",
      "this table, \"None\" means no retrieval data is in-\n",
      "cluded, \"Random Noise\" and \"System Prompt\" de-\n",
      "note adding random characters and protective sys-\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "def format_docs(docs: Document):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "doc_text = format_docs(docs)\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the document: butions and any other form of processing needed\n",
      "for a given evaluation.\n",
      "See listing 4 for a configuration example; it con-\n",
      "tains an answer processor that extracts an answer\n",
      "from an output, and a list of metrics to run.\n",
      "4\n",
      "Experiments: RAG Tuning\n",
      "To illustrate the usage and usefulness of the\n",
      "RAG FOUNDRY library, we experiment with sev-\n",
      "eral possible RAG improvements to LLMs, and\n",
      "evaluate the results on three knowledge-intensive\n",
      "tasks.\n",
      "4.1\n",
      "RAG Augmentation Techniques\n",
      "\n",
      "RAG\n",
      "0.876\n",
      "0.821\n",
      "0.836\n",
      "0.294\n",
      "0.685\n",
      "0.895\n",
      "0.530\n",
      "0.281\n",
      "-\n",
      "-\n",
      "RAG-sft\n",
      "0.878\n",
      "0.777\n",
      "0.750\n",
      "0.252\n",
      "0.717\n",
      "0.833\n",
      "0.720\n",
      "0.491\n",
      "-\n",
      "-\n",
      "CoT\n",
      "0.923\n",
      "0.555\n",
      "0.741\n",
      "0.367\n",
      "0.263\n",
      "0.826\n",
      "0.574\n",
      "0.439\n",
      "0.477\n",
      "0.705\n",
      "CoT-sft\n",
      "0.795\n",
      "0.793\n",
      "0.749\n",
      "0.386\n",
      "0.749\n",
      "0.839\n",
      "0.620\n",
      "0.458\n",
      "0.631\n",
      "0.853\n",
      "Llama-3 8B\n",
      "Baseline\n",
      "0.722\n",
      "-\n",
      "-\n",
      "0.200\n",
      "-\n",
      "-\n",
      "0.560\n",
      "0.366\n",
      "-\n",
      "-\n",
      "RAG\n",
      "0.828\n",
      "0.783\n",
      "0.746\n",
      "0.285\n",
      "0.610\n",
      "0.861\n",
      "0.556\n",
      "0.398\n",
      "-\n",
      "-\n",
      "RAG-sft\n",
      "0.916\n",
      "0.704\n",
      "0.714\n",
      "0.291\n",
      "0.653\n",
      "0.854\n",
      "0.770\n",
      "0.537\n",
      "-\n",
      "-\n",
      "CoT\n",
      "0.896\n",
      "0.518\n",
      "0.764\n",
      "0.395\n",
      "0.536\n",
      "0.730\n",
      "0.684\n",
      "0.480\n",
      "0.378\n",
      "0.732\n",
      "CoT-sft\n",
      "0.851\n",
      "0.808\n",
      "0.697\n",
      "\n",
      "able at https://github.com/phycholosogy/RAG-\n",
      "privacy.\n",
      "1\n",
      "Introduction\n",
      "Retrieval-augmented generation (RAG) (Liu, 2022;\n",
      "Chase, 2022; Van Veen et al., 2023; Ram et al.,\n",
      "2023; Shi et al., 2023) is an advanced natural lan-\n",
      "guage processing technique that enhances text gen-\n",
      "eration by integrating information retrieved from\n",
      "a large corpus of documents. These techniques\n",
      "enable RAG to produce accurate and contextually\n",
      "relevant outputs with augmented external knowl-\n",
      "edge and have been widely used in various scenar-\n",
      "\n",
      "> > >\n",
      "{Retrieved Context}\n",
      "> > >\n",
      "Extracted relevant parts:\n",
      "the query during the summary, while making minimal modifications to the context. Therefore, we created\n",
      "the following two prompts:\n",
      "When summarizing, each extracted context and its corresponding query are placed in the respective\n",
      "positions above.\n",
      "A.3\n",
      "Performance Evaluation\n",
      "For different datasets, we have employed various methods to assess performance of RAG. For each dataset,\n",
      "\n",
      "None\n",
      "245\n",
      "27\n",
      "34\n",
      "-\n",
      "-\n",
      "-\n",
      "213\n",
      "Random Noise+prompt\n",
      "62\n",
      "17\n",
      "24\n",
      "-\n",
      "-\n",
      "-\n",
      "211\n",
      "System Prompt+prompt\n",
      "252\n",
      "7\n",
      "24\n",
      "-\n",
      "-\n",
      "-\n",
      "203\n",
      "RAG-Chatdoctor\n",
      "2\n",
      "1\n",
      "15\n",
      "0\n",
      "0\n",
      "3\n",
      "34\n",
      "RAG-Wikitext\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "70\n",
      "RAG-W3C-Email\n",
      "4\n",
      "17\n",
      "21\n",
      "20\n",
      "65\n",
      "66\n",
      "33\n",
      "content7 to the inputs.\n",
      "5.2\n",
      "Targeted Attack\n",
      "We performed targeted attacks as described in Sec-\n",
      "tion 3.3 and the results are shown in Table 3. In\n",
      "this table, \"None\" means no retrieval data is in-\n",
      "cluded, \"Random Noise\" and \"System Prompt\" de-\n",
      "note adding random characters and protective sys-\n",
      "\n",
      "Here is the question: What is rag?\n",
      "\n",
      "Respond in JSON format with only one key:\n",
      "\"binary_answer\": \"yes\" if relevant, \"no\" if not relevant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils.prompts import doc_grader_prompt, doc_grader_instructions\n",
    "\n",
    "\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_text, question=question\n",
    ")\n",
    "print(doc_grader_prompt_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'binary_answer': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "result = llm_json.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "\n",
    "print(json.loads(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG stands for Retrieval-Augmented Generation, a natural language processing technique that enhances text generation by integrating information retrieved from a large corpus of documents. It produces accurate and contextually relevant outputs with augmented external knowledge. RAG was first introduced in 2022 and has been widely used in various scenarios to improve the quality of generated texts.\n"
     ]
    }
   ],
   "source": [
    "from src.utils.prompts import rag_instructions\n",
    "\n",
    "question = \"What is rag?\"\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "rag_prompt = rag_instructions.format(context=format_docs(docs), question=question)\n",
    "\n",
    "result = llm.invoke([HumanMessage(content=rag_prompt)])\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_answer': 'YES',\n",
       " 'explanation': 'The student answer is grounded in facts as it correctly states that RAG stands for Retrieval-Augmented Generation, a natural language processing technique that enhances text generation by integrating information retrieved from a large corpus of documents. The statement also mentions that RAG produces accurate and contextually relevant outputs with augmented external knowledge. However, the student answer lacks specific details about the introduction year (it was actually introduced in 2022) and does not provide any references to the original sources mentioned in the text.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.prompts import hallucination_grader_instructions, hallucination_grader_prompt\n",
    "\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "    documents=format_docs(docs), answer=result.content\n",
    ")\n",
    "\n",
    "result = llm_json.invoke(\n",
    "    [SystemMessage(content=hallucination_grader_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_answer': 'yes',\n",
       " 'explanation': 'The Student Answer meets all the criteria because it provides a clear and concise definition of RAG, explaining its purpose and application in natural language processing. The answer also addresses the question directly, providing relevant information about what RAG stands for.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.prompts import answer_grader_instructions, answer_grader_prompt\n",
    "\n",
    "question = \"what is rag?\"\n",
    "answer = \"\"\"\n",
    "RAG stands for Retrieval-Augmented Generation, a machine learning approach that combines retrieval and generation techniques, primarily used in natural language processing (NLP). \n",
    "It is particularly effective for tasks like question answering, summarization, and generating responses based on external knowledge.\n",
    "\"\"\"\n",
    "\n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "    question=question, generated_response=answer\n",
    ")\n",
    "\n",
    "result = llm_json.invoke(\n",
    "    [SystemMessage(content=answer_grader_instructions)]\n",
    "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    ")\n",
    "\n",
    "json.loads(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
